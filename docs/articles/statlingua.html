<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>statlingua • statlingua</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="statlingua">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">statlingua</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/statlingua.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/bgreenwell/statlingua/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>statlingua</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/bgreenwell/statlingua/blob/HEAD/vignettes/statlingua.Rmd" class="external-link"><code>vignettes/statlingua.Rmd</code></a></small>
      <div class="d-none name"><code>statlingua.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/bgreenwell/statlingua" class="external-link">statlingua</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="example-inappropriate-use-of-two-sample-t-test">Example: inappropriate use of two-sample t-test<a class="anchor" aria-label="anchor" href="#example-inappropriate-use-of-two-sample-t-test"></a>
</h2>
<p>The following example is taken from a <a href="https://www.jmp.com/en/statistics-knowledge-portal/t-test/paired-t-test" class="external-link">tutorial
on paired t-tests</a>. Here we use an independent two-sample t-test to
(inappropriately) analyze paired data.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">context</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">An instructor wants to use two exams in her classes next year. This year, she gives both exams to the students. She wants to know if the exams are equally difficult and wants to check this by comparing the two sets of scores. Here is the data:</span></span>
<span><span class="st"></span></span>
<span><span class="st"> student exam_1_score exam_2_score</span></span>
<span><span class="st">     Bob           63           69</span></span>
<span><span class="st">    Nina           65           65</span></span>
<span><span class="st">     Tim           56           62</span></span>
<span><span class="st">    Kate          100           91</span></span>
<span><span class="st">  Alonzo           88           78</span></span>
<span><span class="st">    Jose           83           87</span></span>
<span><span class="st">  Nikhil           77           79</span></span>
<span><span class="st">   Julia           92           88</span></span>
<span><span class="st">   Tohru           90           85</span></span>
<span><span class="st"> Michael           84           92</span></span>
<span><span class="st">    Jean           68           69</span></span>
<span><span class="st">   Indra           74           81</span></span>
<span><span class="st">   Susan           87           84</span></span>
<span><span class="st">   Allen           64           75</span></span>
<span><span class="st">    Paul           71           84</span></span>
<span><span class="st">  Edwina           88           82</span></span>
<span><span class="st">"</span></span>
<span></span>
<span><span class="co"># Create the data set</span></span>
<span><span class="va">exam_scores</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tribble.html" class="external-link">tribble</a></span><span class="op">(</span></span>
<span>  <span class="op">~</span><span class="va">student</span>,  <span class="op">~</span><span class="va">exam_1_score</span>, <span class="op">~</span><span class="va">exam_2_score</span>,</span>
<span>  <span class="st">"Bob"</span>,     <span class="fl">63</span>,            <span class="fl">69</span>,</span>
<span>  <span class="st">"Nina"</span>,    <span class="fl">65</span>,            <span class="fl">65</span>,</span>
<span>  <span class="st">"Tim"</span>,     <span class="fl">56</span>,            <span class="fl">62</span>,</span>
<span>  <span class="st">"Kate"</span>,    <span class="fl">100</span>,           <span class="fl">91</span>,</span>
<span>  <span class="st">"Alonzo"</span>,  <span class="fl">88</span>,            <span class="fl">78</span>,</span>
<span>  <span class="st">"Jose"</span>,    <span class="fl">83</span>,            <span class="fl">87</span>,</span>
<span>  <span class="st">"Nikhil"</span>,  <span class="fl">77</span>,            <span class="fl">79</span>,</span>
<span>  <span class="st">"Julia"</span>,   <span class="fl">92</span>,            <span class="fl">88</span>,</span>
<span>  <span class="st">"Tohru"</span>,   <span class="fl">90</span>,            <span class="fl">85</span>,</span>
<span>  <span class="st">"Michael"</span>, <span class="fl">84</span>,            <span class="fl">92</span>,</span>
<span>  <span class="st">"Jean"</span>,    <span class="fl">68</span>,            <span class="fl">69</span>,</span>
<span>  <span class="st">"Indra"</span>,   <span class="fl">74</span>,            <span class="fl">81</span>,</span>
<span>  <span class="st">"Susan"</span>,   <span class="fl">87</span>,            <span class="fl">84</span>,</span>
<span>  <span class="st">"Allen"</span>,   <span class="fl">64</span>,            <span class="fl">75</span>,</span>
<span>  <span class="st">"Paul"</span>,    <span class="fl">71</span>,            <span class="fl">84</span>,</span>
<span>  <span class="st">"Edwina"</span>,  <span class="fl">88</span>,            <span class="fl">82</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Run a two-sample t-test</span></span>
<span><span class="op">(</span><span class="va">tt</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/t.test.html" class="external-link">t.test</a></span><span class="op">(</span><span class="va">exam_scores</span><span class="op">$</span><span class="va">exam_1_score</span>, y <span class="op">=</span> <span class="va">exam_scores</span><span class="op">$</span><span class="va">exam_2_score</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Welch Two Sample t-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  exam_scores$exam_1_score and exam_scores$exam_2_score</span></span>
<span><span class="co">#&gt; t = -0.33602, df = 27.307, p-value = 0.7394</span></span>
<span><span class="co">#&gt; alternative hypothesis: true difference in means is not equal to 0</span></span>
<span><span class="co">#&gt; 95 percent confidence interval:</span></span>
<span><span class="co">#&gt;  -9.322782  6.697782</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; mean of x mean of y </span></span>
<span><span class="co">#&gt;   78.1250   79.4375</span></span></code></pre></div>
<p>Next, we initialize a call the <code><a href="../reference/explain.html">explain()</a></code> method to
explain the output from the statistical test.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Explain the output</span></span>
<span><span class="va">chat</span> <span class="op">&lt;-</span> <span class="fu">ellmer</span><span class="fu">::</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_gemini.html" class="external-link">chat_gemini</a></span><span class="op">(</span>echo <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Using <span style="color: #00BB00;">model</span> = <span style="color: #0000BB;">"gemini-2.0-flash"</span>.</span></span>
<span><span class="va">ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span><span class="va">tt</span>, chat <span class="op">=</span> <span class="va">chat</span>, context <span class="op">=</span> <span class="va">context</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">ex</span><span class="op">)</span></span></code></pre></div>
<p>Okay, here’s a breakdown of the Welch Two Sample t-test output, along
with explanations and context:</p>
<div class="section level3">
<h3 id="summary-of-the-statistical-test">1. Summary of the Statistical Test<a class="anchor" aria-label="anchor" href="#summary-of-the-statistical-test"></a>
</h3>
<ul>
<li>
<strong>Name:</strong> Welch Two Sample t-test (also known as an
independent samples t-test with unequal variances).</li>
<li>
<strong>Purpose:</strong> This test is used to compare the means of
two independent groups. In this case, we’re comparing the mean score on
<code>exam_1_score</code> to the mean score on
<code>exam_2_score</code>. Because it is a Welch’s t-test, the test does
<em>not</em> assume that the variances of the two groups are equal.</li>
<li>
<strong>Key Assumptions:</strong>
<ul>
<li>The data for each group should be approximately normally
distributed.</li>
<li>The two groups (<code>exam_1_score</code> and
<code>exam_2_score</code>) are independent of each other.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="appropriateness-of-the-statistical-test">2. Appropriateness of the Statistical Test<a class="anchor" aria-label="anchor" href="#appropriateness-of-the-statistical-test"></a>
</h3>
<p>Based on the context, the Welch Two Sample t-test appears to be a
reasonable choice. The instructor wants to compare the difficulty of two
exams by comparing the scores achieved by students on each exam. The
scores from the two exams represent two independent groups (assuming
each student took both exams, which the data seem to indicate). The
Welch t-test is appropriate because it does not assume equal variances
between the two exam scores, which is a good choice considering the
exams might have differing score distributions.</p>
</div>
<div class="section level3">
<h3 id="suggestions-for-checking-assumptions-of-the-statistical-test">3. Suggestions for Checking Assumptions of the Statistical Test<a class="anchor" aria-label="anchor" href="#suggestions-for-checking-assumptions-of-the-statistical-test"></a>
</h3>
<ul>
<li>
<strong>Normality:</strong>
<ul>
<li>
<strong>Histograms:</strong> Create histograms of
<code>exam_1_score</code> and <code>exam_2_score</code> separately. Look
for approximate bell shapes. Significant departures from normality
(skewness, multiple peaks) could be a concern.</li>
<li>
<strong>Q-Q Plots:</strong> Create quantile-quantile (Q-Q) plots for
each exam score. These plot the quantiles of your sample data against
the quantiles of a theoretical normal distribution. If the data are
approximately normal, the points will fall close to a straight diagonal
line. Deviations from the line indicate departures from normality.</li>
<li>
<strong>Shapiro-Wilk Test:</strong> You could use the
<code><a href="https://rdrr.io/r/stats/shapiro.test.html" class="external-link">shapiro.test()</a></code> function in R to formally test for normality
in each group. However, be cautious when interpreting the results,
especially with small sample sizes, as the test can be overly sensitive.
Use the graphical methods in combination with this test for a more
complete picture.</li>
</ul>
</li>
<li>
<strong>Independence:</strong> This assumption relies on the study
design. Since each student took both exams, the independence assumption
is likely met.</li>
<li>
<strong>Equality of Variances:</strong> The Welch t-test is used
when the assumption of equal variances is violated. To assess whether
the variances are significantly different, you can use graphical
methods, and Levene’s test or the F-test. Since the Welch’s t-test was
performed, it is likely the assumption of equal variances was not
tenable.</li>
</ul>
</div>
<div class="section level3">
<h3 id="interpretation-of-the-output">4. Interpretation of the Output<a class="anchor" aria-label="anchor" href="#interpretation-of-the-output"></a>
</h3>
<ul>
<li>
<strong><code>t = -0.33602</code>:</strong> This is the calculated
t-statistic. It represents the difference between the sample means,
scaled by the standard error of the difference. The further this value
is from zero (in either the positive or negative direction), the
stronger the evidence against the null hypothesis.</li>
<li>
<strong><code>df = 27.307</code>:</strong> This represents the
degrees of freedom for the test. Because the Welch t-test does not
assume equal variances, the degrees of freedom are calculated using a
more complex formula that results in fractional degrees of freedom.</li>
<li>
<strong><code>p-value = 0.7394</code>:</strong> This is the p-value
associated with the t-statistic. It represents the probability of
observing a t-statistic as extreme as, or more extreme than, the one
calculated (-0.33602), <em>assuming that there is no true difference in
the means of the two exam scores (i.e., assuming the null hypothesis is
true)</em>. A large p-value suggests that the observed data are
reasonably likely to occur even if the null hypothesis is true.</li>
<li>
<strong><code>alternative hypothesis: true difference in means is not equal to 0</code>:</strong>
This states the alternative hypothesis being tested. In this case, the
instructor is testing whether the means of the two exam scores are
<em>different</em>. A one-sided test could be conducted if the
instructor had <em>a priori</em> reasons to believe a certain exam had a
higher mean score than the other.</li>
<li>
<strong><code>95 percent confidence interval: -9.322782 6.697782</code>:</strong>
This is the 95% confidence interval for the <em>difference</em> in the
means of the two exam scores (exam 1 - exam 2). It suggests that we can
be 95% confident that the true difference in means lies between -9.32
and 6.70. Note that this interval includes zero, which is consistent
with the high p-value. Since the confidence interval includes 0, we
cannot reject the null hypothesis that the true mean difference is
0.</li>
<li>
<strong><code>sample estimates: mean of x = 78.1250, mean of y = 79.4375</code>:</strong>
These are the sample means for <code>exam_1_score</code> (x) and
<code>exam_2_score</code> (y) respectively. The mean score on exam 1 is
78.125, and the mean score on exam 2 is 79.4375.</li>
</ul>
</div>
<div class="section level3">
<h3 id="overall-conclusion">5. Overall conclusion<a class="anchor" aria-label="anchor" href="#overall-conclusion"></a>
</h3>
<p>Based on the Welch Two Sample t-test output, with a p-value of
0.7394, there is <em>insufficient evidence to reject the null
hypothesis</em> at a significance level of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>=</mo><mn>0.05</mn></mrow><annotation encoding="application/x-tex">\alpha = 0.05</annotation></semantics></math>.
We conclude that there is not a statistically significant difference in
the mean scores between <code>exam_1_score</code> and
<code>exam_2_score</code>. In other words, based on this analysis, we
don’t have enough evidence to say that the exams are of different
difficulty.</p>
</div>
<div class="section level3">
<h3 id="caution">6. Caution<a class="anchor" aria-label="anchor" href="#caution"></a>
</h3>
<p>This explanation was generated by a Large Language Model. Critically
review the output and consult additional statistical resources or
experts to ensure correctness and a full understanding.</p>
</div>
</div>
<div class="section level2">
<h2 id="example-polynomial-regression">Example: polynomial regression<a class="anchor" aria-label="anchor" href="#example-polynomial-regression"></a>
</h2>
<p>The following example fits a quadradic linear model to the built-in
<code>cars</code> data set.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Polynomial regression</span></span>
<span><span class="va">cars_lm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">dist</span> <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/poly.html" class="external-link">poly</a></span><span class="op">(</span><span class="va">speed</span>, degree <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>, data <span class="op">=</span> <span class="va">cars</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">cars_lm</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; lm(formula = dist ~ poly(speed, degree = 2), data = cars)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residuals:</span></span>
<span><span class="co">#&gt;     Min      1Q  Median      3Q     Max </span></span>
<span><span class="co">#&gt; -28.720  -9.184  -3.188   4.628  45.152 </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;                          Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span><span class="co">#&gt; (Intercept)                42.980      2.146  20.026  &lt; 2e-16 ***</span></span>
<span><span class="co">#&gt; poly(speed, degree = 2)1  145.552     15.176   9.591 1.21e-12 ***</span></span>
<span><span class="co">#&gt; poly(speed, degree = 2)2   22.996     15.176   1.515    0.136    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Residual standard error: 15.18 on 47 degrees of freedom</span></span>
<span><span class="co">#&gt; Multiple R-squared:  0.6673, Adjusted R-squared:  0.6532 </span></span>
<span><span class="co">#&gt; F-statistic: 47.14 on 2 and 47 DF,  p-value: 5.852e-12</span></span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">context</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">The data give the speed of cars (mph) and the distances taken to stop (ft).</span></span>
<span><span class="st">Note that the data were recorded in the 1920s.</span></span>
<span><span class="st">"</span></span>
<span><span class="va">chat</span> <span class="op">&lt;-</span> <span class="fu">ellmer</span><span class="fu">::</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_gemini.html" class="external-link">chat_gemini</a></span><span class="op">(</span>echo <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Using <span style="color: #00BB00;">model</span> = <span style="color: #0000BB;">"gemini-2.0-flash"</span>.</span></span>
<span><span class="va">ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span><span class="va">cars_lm</span>, chat <span class="op">=</span> <span class="va">chat</span>, context <span class="op">=</span> <span class="va">context</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">ex</span><span class="op">)</span></span></code></pre></div>
<p>Here’s an explanation of the linear regression model output you
provided.</p>
<div class="section level3">
<h3 id="summary-of-the-statistical-model">1. Summary of the Statistical Model<a class="anchor" aria-label="anchor" href="#summary-of-the-statistical-model"></a>
</h3>
<ul>
<li><p><strong>Statistical Model:</strong> This is a linear regression
model with a polynomial term of degree 2 for the <code>speed</code>
variable. This is sometimes called a quadratic regression
model.</p></li>
<li><p><strong>Purpose:</strong> Linear regression aims to model the
relationship between a dependent variable (in this case,
<code>dist</code>, the stopping distance of cars) and one or more
independent variables (here, <code>speed</code>) by fitting a linear
equation to the observed data. The polynomial term allows for a
non-linear, specifically quadratic, relationship between speed and
stopping distance.</p></li>
<li>
<p><strong>Key Assumptions:</strong></p>
<ul>
<li>
<strong>Linearity:</strong> The relationship between the independent
variables (or in this case, the polynomial terms of the independent
variable) and the <em>mean</em> of the dependent variable is
linear.</li>
<li>
<strong>Independence of Errors:</strong> The errors (residuals) are
independent of each other. This means that the error for one observation
should not predict the error for another observation.</li>
<li>
<strong>Homoscedasticity (Constant Variance of Errors):</strong> The
variance of the errors is constant across all levels of the independent
variables.</li>
<li>
<strong>Normality of Errors:</strong> The errors are normally
distributed.</li>
<li>
<strong>Independent variables are measured without error:</strong>
The predictor variable, speed, is measured accurately.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="appropriateness-of-the-statistical-model">2. Appropriateness of the Statistical Model<a class="anchor" aria-label="anchor" href="#appropriateness-of-the-statistical-model"></a>
</h3>
<p>Given the context that the data were recorded in the 1920s, using a
model that relates car speed to stopping distance is reasonable. A
quadratic term is included for the speed variable, which suggests that
the analyst believes that the relationship between car speed and
stopping distance is not a simple linear relationship. It is reasonable
to believe that at higher speeds, stopping distance may increase more
quickly than it does at lower speeds. In other words, the analyst
suspects that the rate of change of stopping distance as speed increases
is not constant.</p>
<p>However, some of the assumptions of linear regression may not hold.
For example, it is possible that the variance of the errors is not
constant across all levels of speed. This could happen if the
measurement error in stopping distance is larger at higher speeds. In
addition, it is possible that the errors are not normally distributed.
This could happen if there are outliers in the data or if the
relationship between speed and stopping distance is not truly
quadratic.</p>
</div>
<div class="section level3">
<h3 id="suggestions-for-checking-assumptions-of-the-statistical-model">3. Suggestions for Checking Assumptions of the Statistical
Model<a class="anchor" aria-label="anchor" href="#suggestions-for-checking-assumptions-of-the-statistical-model"></a>
</h3>
<p>It is important to check the assumptions of the linear regression
model to ensure that the results are valid. Here are some suggestions
for checking the assumptions:</p>
<ul>
<li>
<strong>Linearity:</strong>
<ul>
<li>
<strong>Scatter plot of <code>dist</code>
vs. <code>speed</code>:</strong> Check if the relationship appears
roughly linear <em>after</em> accounting for the quadratic term. If the
data shows a clear curve even <em>after</em> including the quadratic
term, the model may not be appropriate.</li>
<li>
<strong>Plot of residuals vs. fitted values:</strong> This is a
crucial plot. Look for any systematic patterns (e.g., a curve) in the
residuals. A random scatter of points indicates that the linearity
assumption is likely met.</li>
</ul>
</li>
<li>
<strong>Independence of Errors:</strong>
<ul>
<li>This is difficult to assess without more information about how the
data were collected. If the data were collected over time, a time series
plot of the residuals could reveal autocorrelation (dependence) in the
errors. The Durbin-Watson test can be used to formally test for
autocorrelation.</li>
<li>Consider whether there are any factors that might cause the stopping
distance of one car to influence the stopping distance of another. If
the cars are measured independently, this assumption may be met.</li>
</ul>
</li>
<li>
<strong>Homoscedasticity (Constant Variance of Errors):</strong>
<ul>
<li>
<strong>Plot of residuals vs. fitted values:</strong> Look for a
“funnel” shape, where the spread of the residuals increases or decreases
as the fitted values change. A constant spread indicates
homoscedasticity.</li>
<li>
<strong>Scale-Location Plot:</strong> This plot (also known as the
spread-level plot) is another way to visualize the homogeneity of
variance. Look for a horizontal line with equally spread points.</li>
<li>
<strong>Brown-Forsythe test:</strong> This is a statistical test for
homogeneity of variance. Use it as a supplement to the graphical
methods.</li>
</ul>
</li>
<li>
<strong>Normality of Errors:</strong>
<ul>
<li>
<strong>Histogram of residuals:</strong> Check if the distribution
of the residuals is approximately normal (bell-shaped).</li>
<li>
<strong>Quantile-Quantile (Q-Q) plot of residuals:</strong> This is
the most important plot for assessing normality. If the residuals are
normally distributed, the points will fall approximately along a
straight diagonal line. Deviations from the line indicate departures
from normality.</li>
<li>
<strong>Shapiro-Wilk test:</strong> This is a statistical test for
normality. Like other tests, use it in conjunction with the Q-Q
plot.</li>
</ul>
</li>
<li>
<strong>Independent variables are measured without error:</strong>
<ul>
<li>Consider the process used to measure the speed of the cars in the
1920s. Was the measurement process accurate? Is there any reason to
believe that this variable may be measured with a large degree of error?
If so, consider the consequences of error in the independent variable on
the resulting statistical model.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="interpretation-of-the-output-1">4. Interpretation of the Output<a class="anchor" aria-label="anchor" href="#interpretation-of-the-output-1"></a>
</h3>
<ul>
<li>
<p><strong>Call:</strong>
<code>lm(formula = dist ~ poly(speed, degree = 2), data = cars)</code></p>
<ul>
<li>This simply restates the model you fit. It says that you are
modeling <code>dist</code> as a function of <code>speed</code>, where
the <code>speed</code> variable is included as a polynomial of degree
2.</li>
</ul>
</li>
<li>
<p><strong>Residuals:</strong></p>
<ul>
<li>These are the differences between the actual stopping distances
(<code>dist</code>) and the stopping distances predicted by the
model.</li>
<li>The summary (Min, 1Q, Median, 3Q, Max) gives you an idea of the
distribution of the residuals. Ideally, the median should be close to
zero, and the distribution should be roughly symmetric. The min and max
values give the range of the residuals.</li>
</ul>
</li>
<li>
<p><strong>Coefficients:</strong></p>
<ul>
<li>
<strong>(Intercept): Estimate = 42.980, Std. Error = 2.146, t value
= 20.026, Pr(&gt;|t|) &lt; 2e-16</strong>
<ul>
<li>
<strong>Estimate:</strong> The estimated intercept is 42.980. Since
the <code>speed</code> variable has been transformed using orthogonal
polynomials, the intercept represents the expected value of
<code>dist</code> when the orthogonal polynomials are equal to zero.
This value is not particularly useful, but it is a necessary part of the
statistical model.</li>
<li>
<strong>Std. Error:</strong> The standard error of the intercept is
2.146. This is a measure of the uncertainty in the estimate of the
intercept.</li>
<li>
<strong>t value:</strong> The t-statistic for the intercept is
20.026. This is the estimate divided by the standard error, which can be
used to assess whether the intercept is statistically different from
zero.</li>
<li>
<strong>Pr(&gt;|t|):</strong> The p-value is less than 2e-16 (which
is a very small number, essentially zero). This means that if the true
intercept were zero, the probability of observing a t-statistic as
extreme as 20.026 (in either the positive or negative direction) would
be virtually zero. Thus, we have strong evidence that the intercept is
not zero.</li>
</ul>
</li>
<li>
<strong>poly(speed, degree = 2)1: Estimate = 145.552, Std. Error =
15.176, t value = 9.591, Pr(&gt;|t|) = 1.21e-12</strong>
<ul>
<li>
<strong>Estimate:</strong> The estimated coefficient for the
first-degree polynomial term of <code>speed</code> is 145.552. Because
the <code>speed</code> variable has been transformed using orthogonal
polynomials, the coefficient estimate does not have a direct
interpretation. However, we can conclude that the first-degree term is
an important part of the model.</li>
<li>
<strong>Std. Error:</strong> The standard error is 15.176.</li>
<li>
<strong>t value:</strong> The t-statistic is 9.591.</li>
<li>
<strong>Pr(&gt;|t|):</strong> The p-value is 1.21e-12 (again,
essentially zero). This indicates strong evidence that this first-degree
polynomial term is significantly associated with <code>dist</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>poly(speed, degree = 2)2: Estimate = 22.996, Std. Error =
15.176, t value = 1.515, Pr(&gt;|t|) = 0.136</strong></p>
<ul>
<li>
<strong>Estimate:</strong> The estimated coefficient for the
second-degree polynomial term of <code>speed</code> is 22.996. Because
the <code>speed</code> variable has been transformed using orthogonal
polynomials, the coefficient estimate does not have a direct
interpretation.</li>
<li>
<strong>Std. Error:</strong> The standard error is 15.176.</li>
<li>
<strong>t value:</strong> The t-statistic is 1.515.</li>
<li>
<strong>Pr(&gt;|t|):</strong> The p-value is 0.136. This suggests
that the second-degree polynomial term is <em>not</em> statistically
significantly associated with <code>dist</code> at the conventional
alpha = 0.05 level.</li>
</ul>
</li>
<li>
<p><strong>Residual standard error: 15.18 on 47 degrees of
freedom</strong></p>
<ul>
<li>This is an estimate of the standard deviation of the errors
(residuals). It represents the typical size of the difference between
the observed values and the values predicted by the model. The degrees
of freedom (47) are calculated as the number of observations (50) minus
the number of parameters estimated in the model (3: intercept, the
first-degree polynomial, and the second-degree polynomial).</li>
</ul>
</li>
<li>
<p><strong>Multiple R-squared: 0.6673, Adjusted R-squared:
0.6532</strong></p>
<ul>
<li>
<strong>Multiple R-squared:</strong> This represents the proportion
of the variance in <code>dist</code> that is explained by the model. In
this case, approximately 66.73% of the variance in stopping distance is
explained by the quadratic relationship with speed.</li>
<li>
<strong>Adjusted R-squared:</strong> This is a modified version of
R-squared that adjusts for the number of predictors in the model. It is
generally a better measure of the goodness of fit, especially when
comparing models with different numbers of predictors. Here, the
adjusted R-squared is 0.6532. The adjusted R-squared will always be less
than or equal to the multiple R-squared.</li>
</ul>
</li>
<li>
<p><strong>F-statistic: 47.14 on 2 and 47 DF, p-value:
5.852e-12</strong></p>
<ul>
<li>The F-statistic tests the overall significance of the model. The
null hypothesis is that <em>all</em> of the coefficients in the model
(except the intercept) are zero. The very small p-value (5.852e-12,
which is essentially zero) indicates strong evidence <em>against</em>
the null hypothesis. This means that at least one of the polynomial
terms of <code>speed</code> is significantly related to
<code>dist</code>. Since the first-degree term is statistically
significant, this result is not surprising.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="additional-considerations">5. Additional Considerations<a class="anchor" aria-label="anchor" href="#additional-considerations"></a>
</h3>
<ul>
<li>In linear regression models, <strong>overdispersion</strong> is
typically not a concern. Overdispersion is usually relevant for
count-based models, such as Poisson or negative binomial
regression.</li>
<li>Since the dependent variable is measured on a continuous scale,
<strong>zero inflation</strong> is not a concern here.</li>
</ul>
</div>
<div class="section level3">
<h3 id="caution-1">6. Caution<a class="anchor" aria-label="anchor" href="#caution-1"></a>
</h3>
<p>This explanation was generated by a Large Language Model. While I
have tried to provide an accurate and helpful interpretation, it is
crucial to critically review the output and consult additional
statistical resources or experts to ensure correctness and a full
understanding.</p>
</div>
</div>
<div class="section level2">
<h2 id="example-poisson-regression">Example: Poisson regression<a class="anchor" aria-label="anchor" href="#example-poisson-regression"></a>
</h2>
<p>The following example uses the generic function
<code><a href="../reference/explain.html">explain()</a></code> to explain the output from a fitted <a href="https://en.wikipedia.org/wiki/Poisson_regression" class="external-link">Poisson GLM</a>
using simple Markdown syntax:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Poisson regression example from ?stats::glm</span></span>
<span><span class="va">counts</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">18</span>,<span class="fl">17</span>,<span class="fl">15</span>,<span class="fl">20</span>,<span class="fl">10</span>,<span class="fl">20</span>,<span class="fl">25</span>,<span class="fl">13</span>,<span class="fl">12</span><span class="op">)</span></span>
<span><span class="va">outcome</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/gl.html" class="external-link">gl</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">1</span>,<span class="fl">9</span><span class="op">)</span></span>
<span><span class="va">treatment</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/gl.html" class="external-link">gl</a></span><span class="op">(</span><span class="fl">3</span>,<span class="fl">3</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html" class="external-link">summary</a></span><span class="op">(</span><span class="va">D93_glm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">counts</span> <span class="op">~</span> <span class="va">outcome</span> <span class="op">+</span> <span class="va">treatment</span>, family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html" class="external-link">poisson</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = counts ~ outcome + treatment, family = poisson())</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;        1         2         3         4         5         6         7         8  </span></span>
<span><span class="co">#&gt; -0.67125   0.96272  -0.16965  -0.21999  -0.95552   1.04939   0.84715  -0.09167  </span></span>
<span><span class="co">#&gt;        9  </span></span>
<span><span class="co">#&gt; -0.96656  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;               Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept)  3.045e+00  1.709e-01  17.815   &lt;2e-16 ***</span></span>
<span><span class="co">#&gt; outcome2    -4.543e-01  2.022e-01  -2.247   0.0246 *  </span></span>
<span><span class="co">#&gt; outcome3    -2.930e-01  1.927e-01  -1.520   0.1285    </span></span>
<span><span class="co">#&gt; treatment2  -3.242e-16  2.000e-01   0.000   1.0000    </span></span>
<span><span class="co">#&gt; treatment3  -2.148e-16  2.000e-01   0.000   1.0000    </span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for poisson family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 10.5814  on 8  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance:  5.1291  on 4  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 56.761</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">chat</span> <span class="op">&lt;-</span> <span class="fu">ellmer</span><span class="fu">::</span><span class="fu"><a href="https://ellmer.tidyverse.org/reference/chat_gemini.html" class="external-link">chat_gemini</a></span><span class="op">(</span>echo <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Using <span style="color: #00BB00;">model</span> = <span style="color: #0000BB;">"gemini-2.0-flash"</span>.</span></span>
<span><span class="va">ex</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/explain.html">explain</a></span><span class="op">(</span><span class="va">D93_glm</span>, chat <span class="op">=</span> <span class="va">chat</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="va">ex</span><span class="op">)</span></span></code></pre></div>
<p>Here’s an explanation of the Poisson regression output you
provided.</p>
<div class="section level3">
<h3 id="summary-of-the-statistical-model-1">1. Summary of the Statistical Model<a class="anchor" aria-label="anchor" href="#summary-of-the-statistical-model-1"></a>
</h3>
<ul>
<li>
<strong>Name:</strong> Poisson Regression with a log link
function.</li>
<li>
<strong>Purpose:</strong> Poisson regression is used to model count
data. Specifically, it models the <em>rate</em> at which events occur.
The log link function ensures that the predicted counts are always
positive by modeling the logarithm of the expected count as a linear
function of the predictors.</li>
<li>
<strong>Key Assumptions:</strong>
<ul>
<li>The response variable (counts) follows a Poisson distribution. This
means the variance is equal to the mean.</li>
<li>The observations are independent of each other.</li>
<li>The logarithm of the expected count is linearly related to the
predictors.</li>
<li>No overdispersion (the variance is not greater than the mean) or
underdispersion (the variance is not less than the mean).</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="appropriateness-of-the-statistical-model-1">2. Appropriateness of the Statistical Model<a class="anchor" aria-label="anchor" href="#appropriateness-of-the-statistical-model-1"></a>
</h3>
<p>Without additional context on the data, study design, and research
question, I cannot comment on whether the chosen statistical model is
appropriate. To assess the appropriateness of the Poisson model, you
would need to consider whether your outcome variable is a count, and
whether the assumptions of the Poisson distribution are likely to be
met.</p>
</div>
<div class="section level3">
<h3 id="suggestions-for-checking-assumptions-of-the-statistical-model-1">3. Suggestions for Checking Assumptions of the Statistical
Model<a class="anchor" aria-label="anchor" href="#suggestions-for-checking-assumptions-of-the-statistical-model-1"></a>
</h3>
<p>It’s essential to check the assumptions of the Poisson regression
model. Here’s how:</p>
<ul>
<li>
<strong>Independence:</strong> This is usually determined by the
study design. Were the observations collected independently?</li>
<li>
<strong>Linearity:</strong> You can’t directly check the linearity
of the relationship between the predictors and the <em>counts</em>
because the model assumes a linear relationship between the predictors
and the <em>log of the counts</em>. You could assess this by plotting
the residuals against the predicted values or against each predictor.
Look for patterns in the residuals, which would indicate a violation of
linearity.</li>
<li>
<strong>Checking the Poisson Distribution and
Overdispersion:</strong>
<ul>
<li>
<strong>Residual Plots:</strong> Create a plot of the residuals
versus the fitted values. In a well-fitting Poisson model, the residuals
should be randomly scattered around zero, with no apparent patterns or
trends. Funneling or other non-random patterns suggest a problem.</li>
<li>
<strong>Quantile-Quantile (QQ) Plot:</strong> Create a QQ plot of
the residuals against a theoretical normal distribution.</li>
<li>
<strong>Variance vs. Mean:</strong> Compare the variance and mean of
your outcome variable (counts). In a Poisson distribution, these should
be approximately equal. If the variance is much larger than the mean,
overdispersion is a concern.</li>
<li>
<strong>Overdispersion test:</strong> A useful rule of thumb is to
divide the residual deviance by the residual degrees of freedom. In your
case, this would be 5.1291 / 4 = 1.282. A value much larger than 1
suggests overdispersion, which may be a problem. However, as a rule of
thumb, this number is not excessively large.</li>
</ul>
</li>
</ul>
<p>While formal statistical tests for overdispersion exist, graphical
methods are generally more informative for understanding the nature of
any violations.</p>
</div>
<div class="section level3">
<h3 id="interpretation-of-the-output-2">4. Interpretation of the Output<a class="anchor" aria-label="anchor" href="#interpretation-of-the-output-2"></a>
</h3>
<p>Here’s an interpretation of the output you provided:</p>
<ul>
<li>
<p><strong>Call:</strong>
<code>glm(formula = counts ~ outcome + treatment, family = poisson())</code></p>
<ul>
<li>This confirms that you used the <code>glm</code> function in R to
fit a generalized linear model. The formula indicates that you are
modeling <code>counts</code> as a function of <code>outcome</code> and
<code>treatment</code>, using a Poisson distribution.</li>
</ul>
</li>
<li>
<p><strong>Deviance Residuals:</strong></p>
<ul>
<li>Deviance residuals are a measure of how well each data point fits
the model. Large positive or negative values indicate a poor fit for
those particular observations. Since there are only 9 data points, it is
hard to assess these, but the values seem reasonable.</li>
</ul>
</li>
<li>
<p><strong>Coefficients:</strong></p>
<ul>
<li>
<strong>(Intercept): 3.045e+00</strong>
<ul>
<li>This is the estimated log of the expected count when
<code>outcome</code> and <code>treatment</code> are at their baseline
levels (i.e., <code>outcome1</code> and <code>treatment1</code> since
<code>outcome</code> and <code>treatment</code> are categorical
variables). In other words, when <code>outcome</code> is
<code>outcome1</code> and <code>treatment</code> is
<code>treatment1</code>, the estimated log count is 3.045.
Exponentiating this value (<code>exp(3.045) ≈ 21.00</code>) gives the
estimated expected count (21.00) when both <code>outcome</code> and
<code>treatment</code> are at their baseline levels.</li>
</ul>
</li>
<li>
<strong>outcome2: -4.543e-01</strong>
<ul>
<li>This is the estimated change in the log of the expected count when
<code>outcome</code> is <code>outcome2</code>, <em>holding
<code>treatment</code> constant</em>. Since the outcome coefficient is
negative, this means that the expected count for <code>outcome2</code>
is <em>lower</em> than for <code>outcome1</code>. To get the count,
exponentiate: <code>exp(-0.4543) = 0.635</code>. Thus, for the same
treatment level, the expected count is 0.635 times lower for outcome2
compared to outcome1.</li>
</ul>
</li>
<li>
<strong>outcome3: -2.930e-01</strong>
<ul>
<li>This is the estimated change in the log of the expected count when
<code>outcome</code> is <code>outcome3</code>, <em>holding
<code>treatment</code> constant</em>. Since the outcome coefficient is
negative, this means that the expected count for <code>outcome3</code>
is <em>lower</em> than for <code>outcome1</code>. To get the count,
exponentiate: <code>exp(-0.2930) = 0.746</code>. Thus, for the same
treatment level, the expected count is 0.746 times lower for outcome3
compared to outcome1.</li>
</ul>
</li>
<li>
<strong>treatment2: -3.242e-16</strong>
<ul>
<li>This is the estimated change in the log of the expected count when
<code>treatment</code> is <code>treatment2</code>, <em>holding
<code>outcome</code> constant</em>. Since the treatment coefficient is
negative, this means that the expected count for <code>treatment2</code>
is <em>lower</em> than for <code>treatment1</code>. Note that this is
effectively zero.</li>
</ul>
</li>
<li>
<strong>treatment3: -2.148e-16</strong>
<ul>
<li>This is the estimated change in the log of the expected count when
<code>treatment</code> is <code>treatment3</code>, <em>holding
<code>outcome</code> constant</em>. Since the treatment coefficient is
negative, this means that the expected count for <code>treatment3</code>
is <em>lower</em> than for <code>treatment1</code>. Note that this is
effectively zero.</li>
</ul>
</li>
<li>
<strong>Std. Error:</strong> The standard error measures the
precision of the estimated coefficients. Smaller standard errors
indicate more precise estimates.</li>
<li>
<strong>z value:</strong> This is the test statistic (z-score) for
the null hypothesis that the coefficient is equal to zero. It is
calculated by dividing the coefficient estimate by its standard
error.</li>
<li>
<strong>Pr(&gt;|z|):</strong> This is the p-value associated with
the z-test. It represents the probability of observing a z-score as
extreme as, or more extreme than, the one calculated, <em>assuming the
null hypothesis is true</em> (i.e., the coefficient is actually zero).
<ul>
<li>For <code>outcome2</code>, the p-value is 0.0246, which is
statistically significant at the 0.05 level. This suggests that there is
evidence that <code>outcome2</code> is associated with a change in the
expected count, compared to <code>outcome1</code> (the baseline).</li>
<li>For <code>outcome3</code>, the p-value is 0.1285, which is not
statistically significant at the 0.05 level. This suggests that there is
not enough evidence to conclude that <code>outcome3</code> is associated
with a change in the expected count, compared to <code>outcome1</code>
(the baseline).</li>
<li>For <code>treatment2</code> and <code>treatment3</code>, the
p-values are 1.0000, which is not statistically significant at the 0.05
level. This suggests that there is not enough evidence to conclude that
<code>treatment2</code> and <code>treatment3</code> are associated with
a change in the expected count, compared to <code>treatment1</code> (the
baseline).</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>(Dispersion parameter for poisson family taken to be
1):</strong> This confirms that the model is assuming the variance
equals the mean, as is standard for Poisson regression. If there is
substantial overdispersion, the dispersion parameter would be estimated
to be larger than 1 in a quasi-Poisson model, and the standard errors of
the coefficients would be inflated.</p></li>
<li>
<p><strong>Null deviance: 10.5814 on 8 degrees of
freedom</strong></p>
<ul>
<li>This measures the deviance of the “null model” (a model with only an
intercept) from the observed data. It indicates how well the null model
fits the data.</li>
</ul>
</li>
<li>
<p><strong>Residual deviance: 5.1291 on 4 degrees of
freedom</strong></p>
<ul>
<li>This measures the deviance of the fitted model from the observed
data. It indicates how well the model with predictors fits the data. A
lower residual deviance indicates a better fit.</li>
</ul>
</li>
<li>
<p><strong>AIC: 56.761</strong></p>
<ul>
<li>AIC (Akaike Information Criterion) is a measure of model fit that
penalizes model complexity. Lower AIC values indicate a better balance
between fit and parsimony. It is useful for comparing different
models.</li>
</ul>
</li>
<li>
<p><strong>Number of Fisher Scoring iterations: 4</strong></p>
<ul>
<li>This indicates the number of iterations the fitting algorithm took
to converge to the maximum likelihood estimates.</li>
</ul>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="additional-considerations-for-this-type-of-model">5. Additional considerations for this type of model:<a class="anchor" aria-label="anchor" href="#additional-considerations-for-this-type-of-model"></a>
</h3>
<ul>
<li>
<strong>Overdispersion:</strong> As mentioned earlier,
overdispersion is a common issue in Poisson regression. Check for this
using the methods described above. If overdispersion is present,
consider using a quasi-Poisson model or a negative binomial regression
model, which can account for the extra variability. The rule-of-thumb
overdispersion check in part 3 above suggests that overdispersion is not
a major concern here.</li>
<li>
<strong>Zero Inflation:</strong> If you have an excess of zeros in
your count data compared to what a Poisson distribution would predict,
you might have zero inflation. You can investigate this by comparing the
observed proportion of zeros to the proportion predicted by the Poisson
model. Zero-inflated Poisson (ZIP) models are available to handle this
situation.</li>
</ul>
</div>
<div class="section level3">
<h3 id="caution-2">6. Caution<a class="anchor" aria-label="anchor" href="#caution-2"></a>
</h3>
<p>This explanation was generated by a Large Language Model. Critically
review the output and consult additional statistical resources or
experts to ensure correctness and a full understanding.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Brandon M. Greenwell.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.2.</p>
</div>

    </footer>
</div>





  </body>
</html>
