---
title: "The statlingua Package"
subtitle: "Using LLMs to Help Explain and Interperate Statistical Output"
from: markdown+emoji
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{The statlingua Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

# Execute the code from the vignette
# knitr::knit("vignettes/statlingua.Rmd.orig", output = "vignettes/statlingua.Rmd")
```

## Introduction

Statistical models are indispensable tools for extracting insights from data, yet their outputs can often be cryptic and laden with technical jargon. Deciphering coefficients, p-values, confidence intervals, and various model fit statistics typically requires a solid statistical background. This can create a barrier when communicating findings to a wider audience or even for those still developing their statistical acumen.

The **statlingua** R package is here to change that\! It masterfully leverages the power of Large Language Models (LLMs) to translate complex statistical model outputs into clear, understandable, and context-aware natural language. By simply feeding your R statistical model objects into **statlingua**, you can generate human-readable interpretations, making statistical understanding accessible to everyone, regardless of their technical expertise.

It's important to note that **statlingua** itself doesn't directly call LLM APIs. Instead, it serves as a sophisticated prompt engineering toolkit. It meticulously prepares the necessary inputs (your model summary and contextual information) and then passes them to the [ellmer](https://cran.r-project.org/package=ellmer) package, which handles the actual communication with the LLM. The primary workhorse function you'll use in **statlingua** is `explain()`.

This vignette will guide you through understanding and using **statlingua** effectively.

## Prerequisites

Before diving in, please ensure you have the following:

1.  The **statlingua** package installed from GitHub (not yet available on CRAN):
```{r statlingua_install, eval=FALSE}
if (!requireNamespace("remotes")) {
  install.packages("remotes")
}
remotes::install_github("bgreenwell/statlingua")
```
2.  The [ellmer](https://cran.r-project.org/package=ellmer) package installed. **statlingua** relies on it for LLM communication:
```{r ellmer_install, eval=FALSE}
install.packages("ellmer")
```
3.  Access to an LLM provider (e.g., OpenAI, Google Gemini, or Anthropic) and a corresponding API key. You'll need to configure your API key according to the [ellmer](https://cran.r-project.org/package=ellmer) package's documentation. This usually involves setting environment variables like `OPENAI_API_KEY`, `GOOGLE_API_KEY`, or `ANTHROPIC_API_KEY`. Note that while While [ellmer](https://cran.r-project.org/package=ellmer) supports numerous LLM providers, **this vignette will specifically use Google Gemini models** via `ellmer::chat_google_gemini()`; I find Google Gemini to be particularly well-suited for explaining statistical output and they offer a generous free tier. You'll need to configure your API key according to the [ellmer](https://cran.r-project.org/package=ellmer) package's documentation. This typically involves setting the `GEMINI_API_KEY` environment variable in your R session or `.Renviron` file (e.g., `Sys.setenv(GEMINI_API_KEY = "YOUR_API_KEY_HERE")`).
4.  For the examples in this vignette, you'll also need the following packages: [ISLR2](https://cran.r-project.org/package=ISLR2), [MASS](https://cran.r-project.org/package=MASS), and [survival](https://cran.r-project.org/package=survival).
```{r other-deps-install, eval=FALSE}
install.packages(c("ISLR2", "jsonlite", "lme4", "MASS", "survival"))
```

## How **statlingua** Works: The `explain()` Function and [ellmer](https://cran.r-project.org/package=ellmer)

The primary function you'll use in ****statlingua**** is `explain()`. This is an S3 generic function, meaning its behavior adapts to the class of the R statistical object you provide (e.g., an `"lm"` object, `"glm"` object, `"lmerMod"` object, etc.).

The process `explain()` follows to generate an interpretation involves several key steps:

1.  **Input & Initial Argument Resolution**:
    You call `explain()` with your statistical `object`, an [ellmer](https://cran.r-project.org/package=ellmer) `client`, and optionally `context`, `audience`, `verbosity`, and the new `style` argument. The `explain()` generic function first resolves `audience`, `verbosity`, and `style` to their specific chosen values (e.g., `audience = "novice"`, `style = "markdown"`) using `match.arg()`. These resolved values are then passed to the appropriate S3 method for the class of your `object`.

2.  **Model Summary Extraction**:
    Internally, `explain()` (typically via the `.explain_core()` helper function or directly in `explain.default()`) uses the `summarize()` function to capture a text-based summary of your statistical `object`. This captured text (e.g., similar to what `summary(object)` would produce) forms the core statistical information that the LLM will interpret.

3.  **System Prompt Assembly (via `.assemble_sys_prompt()`)**:
    This is where **statlingua** constructs the detailed instructions for the LLM. The internal `.assemble_sys_prompt()` function pieces together several components, all read from `.md` files stored within the package's `inst/prompts/` directory. The final system prompt typically includes the following sections, ordered to guide the LLM effectively:

    * **Role Definition**:
        * A base role description is read from `inst/prompts/common/role_base.md`.
        * If available, model-specific role details are appended from `inst/prompts/models/<model_name>/role_specific.md` (where `<model_name>` corresponds to the class of your object, like "lm" or "lmerMod"). If this file doesn't exist for a specific model, this part is omitted.
    * **Intended Audience and Verbosity**:
        * Instructions tailored to the specified `audience` (e.g., `"novice"`, `"researcher"`) are read from `inst/prompts/audience/<audience_value>.md` (e.g., `inst/prompts/audience/novice.md`).
        * Instructions defining the `verbosity` level (e.g., `"brief"`, `"detailed"`) are read from `inst/prompts/verbosity/<verbosity_value>.md` (e.g., `inst/prompts/verbosity/detailed.md`).
    * **Response Format Specification (Style)**:
        * This crucial part is determined by the `style` argument. Instructions for the desired output format (e.g., `"markdown"`, `"html"`, `"json"`, `"text"`, `"latex"`) are read from `inst/prompts/style/<style_value>.md` (e.g., `inst/prompts/style/markdown.md`). This tells the LLM how to structure its entire response.
    * **Model-Specific Instructions**:
        * Detailed instructions on what aspects of the statistical model to explain are read from `inst/prompts/models/<model_name>/instructions.md` (e.g., for an `"lm"` object, it would read from `inst/prompts/models/lm/instructions.md`). If model-specific instructions aren't found, it defaults to `inst/prompts/models/default/instructions.md`.
    * **Cautionary Notes**:
        * A general caution message is appended from `inst/prompts/common/caution.md`.

    These components are assembled into a single, comprehensive system prompt that guides the LLM's behavior, tone, content focus, and output format.

4.  **User Prompt Construction (via `.build_usr_prompt()`)**:
    The "user prompt" (the actual query containing the data to be interpreted) is constructed by combining:
    * A leading phrase indicating the type of model (e.g., "Explain the following linear regression model output:").
    * The captured model `output_summary` from step 2.
    * Any additional `context` string provided by the user via the `context` argument.

5.  **LLM Interaction via [ellmer](https://cran.r-project.org/package=ellmer)**:
    The assembled `sys_prompt` is set for the [ellmer](https://cran.r-project.org/package=ellmer) `client` object. Then, the constructed `usr_prompt` is sent to the LLM using `client$chat(usr_prompt)`. [ellmer](https://cran.r-project.org/package=ellmer) handles the actual API communication.

6.  **Output Post-processing (via `.remove_fences()`)**:
    Before returning the explanation, ****statlingua**** calls an internal utility, `.remove_fences()`, to clean the LLM's raw output. This function attempts to remove common "language fence" wrappers (like ```markdown ... ``` or ```json ... ```) that LLMs sometimes add around their responses.

7.  **Output Packaging**:
    The cleaned explanation string from the LLM is then packaged into a `statlingua_explanation` object. This object's `text` component holds the explanation string in the specified `style`. It also includes metadata like the `model_type`, `audience`, `verbosity`, and `style` used. The `statlingua_explanation` object has a default print method that uses `cat()` for easy viewing in the console.

This comprehensive and modular approach to prompt engineering allows **statlingua** to provide tailored and well-formatted explanations for a variety of statistical models and user needs.

### Understanding `explain()`'s Arguments

The `explain()` function is flexible, with several arguments to fine-tune its behavior:

* `object`: The primary input â€“ your R statistical object (e.g., an `"lm"` model, a `"glm"` model, the output of `t.test()`, `coxph()`, etc.).
* `client`: **Essential**. This is an [ellmer](https://cran.r-project.org/package=ellmer) client object (e.g., created by `ellmer::chat_google_gemini()`). **statlingua** uses this to communicate with the LLM. You must initialize and configure this client with your API key beforehand.
* `context` (Optional but **Highly Recommended**): A character string providing background information about your data, research questions, variable definitions, units, study design, etc. Default is `NULL`.
* `audience` (Optional): Specifies the target audience for the explanation. Options include: `"novice"` (default), `"student"`, `"researcher"`, `"manager"`, `"domain_expert"`.
* `verbosity` (Optional): Controls the level of detail. Options are: `"moderate"` (default), `"brief"`, `"detailed"`.
* `style` (Optional): Character string indicating the desired output style. Defaults to `"markdown"`. Options include:
    * `"markdown"`: Output formatted as Markdown.
    * `"html"`: Output formatted as an HTML fragment.
    * `"json"`: Output structured as a JSON string parseable into an R list (see example for parsing).
    * `"text"`: Output as plain text.
    * `"latex"`: Output as a LaTeX fragment.
* `...` (Optional): Additional optional arguments (currently ignored by **statlingua**'s `explain` methods).

## The Power of `context`: Why It Matters

You *could* just pass your model object to `explain()` and get a basic interpretation. However, to unlock truly insightful and actionable explanations, **providing `context` is paramount.**

LLMs are incredibly powerful, but they don't inherently know the nuances of your specific research. They don't know what "VarX" *really* means in your data set, its units, the specific hypothesis you're testing, or the population you're studying unless you tell them. The `context` argument is your channel to provide this vital background.

What makes for **effective `context`**?

  * **Research Objective**: What question(s) are you trying to answer? (e.g., "We are investigating factors affecting Gentoo penguin bill length to understand dietary adaptations.")
  * **Data Description**:
      * What do your variables represent? Be specific. (e.g., "`bill_length_mm` is the length of the penguin's bill in millimeters.")
      * What are their units? (e.g., "Flipper length is in millimeters, body mass in grams.")
      * Are there any known data limitations or special characteristics? (e.g., "Data collected from three islands in the Palmer Archipelago.")
  * **Study Design**: How was the data collected? (e.g., "Observational data from a field study.")
  * **Target Audience Nuances (Implicitly)**: While the `audience` argument handles the main targeting, mentioning specific interpretation needs in the `context` can further refine the LLM's output (e.g., "Explain the practical significance of these findings for wildlife conservation efforts.").

By supplying such details, you empower the LLM to:

  * Interpret coefficients with their **true, domain-specific meaning**.
  * Relate findings **directly to your research goals**.
  * Offer more **relevant advice** on model assumptions or limitations.
  * Generate explanations that are **less generic, more targeted, and ultimately far more useful**.

Think of `context` as the difference between asking a generic statistician "What does this mean?" versus asking a statistician who deeply understands your research area, data, and objectives. The latter will always provide a more valuable interpretation.

## Some Examples in Action\!

Let's see **statlingua** shine with some practical examples.

**Important Note on API Keys:** The following code chunks that call `explain()` are set to `eval = FALSE` by default in this vignette. This is because they require an active API key configured for [ellmer](https://cran.r-project.org/package=ellmer). To run these examples yourself:

1.  Ensure your API key (e.g., `GOOGLE_API_KEY`, `OPENAI_API_KEY`, or `ANTHROPIC_API_KEY`) is set up as an environment variable that [ellmer](https://cran.r-project.org/package=ellmer) can access.
2.  Change the R chunk option `eval = FALSE` to `eval = TRUE` for the chunks you wish to run.
3.  You may need to adjust the [ellmer](https://cran.r-project.org/package=ellmer) client initialization (e.g., `ellmer::chat_openai()`) to match your chosen LLM provider.

For this examples in this vignette

### Example 1: Linear Regression (`lm`) - Sales of Child Car Seats

Let's use a linear model to predict `Sales` of child car seats from various predictors using the `Carseats` data set from package [ISLR2](https://cran.r-project.org/package=ISLR2). To make this example a bit more complicated, we'll include pairwise interaction effects in the model (you can include polynomial terms, smoothing splines, or any type of transformation that makes sense). Note that the categorical variables `ShelveLoc`, `Urban`, and `US` have been dummy encoded by default).

```{r carseats_lm, eval = TRUE}
data(Carseats, package = "ISLR2")  # load the Carseats data

# Fit a linear model to the Carseats data set
fm_carseats <- lm(Sales ~ . + Price:Age + Income:Advertising, data = Carseats)
summary(fm_carseats)  # print model summary
```

The next code chunk loads the **statlingua** package and establishes a connection to a (default) Google Gemini model. We also define some context for the LLM to use when explaining the above output:

```{r carseats_lm_context}
library(statlingua)

# Establish client connection
client <- ellmer::chat_google_gemini(echo = "none")

# Additional context for the LLM to consider
carseats_context <- "
The model uses a data set on child car seat sales (in thousands of units) at 400 different stores.
The goal is to identify factors associated with sales.
The variables are:
  * Sales: Unit sales (in thousands) at each location (the response variable).
  * CompPrice: Price charged by competitor at each location.
  * Income: Community income level (in thousands of dollars).
  * Advertising: Local advertising budget for the company at each location (in thousands of dollars).
  * Population: Population size in the region (in thousands).
  * Price: Price the company charges for car seats at each site.
  * ShelveLoc: A factor with levels 'Bad', 'Good', and 'Medium' indicating the quality of the shelving location for the car seats. ('Bad' is the reference level).
  * Age: Average age of the local population.
  * Education: Education level at each location.
  * Urban: A factor ('No', 'Yes') indicating if the store is in an urban or rural location. ('No' is the reference level).
  * US: A factor ('No', 'Yes') indicating if the store is in the US or not. ('No' is the reference level).
Interaction terms `Income:Advertising` and `Price:Age` are also included.
The data set is simulated. We want to understand key drivers of sales and how to interpret the interaction terms.
"
```

Next, let's use the Google Gemini model to generate an explanation of the model's output, targeting a `"student"` audience with `"detailed"` verbosity.

```{r carseats_lm_explain, results="asis"}
explain(fm_carseats, client = client, context = carseats_context,
        audience = "novice", verbosity = "detailed")
```


#### Follow-up Question: Interpreting R-squared

The initial explanation is great, but let's say a student wants to understand R-squared more deeply for this particular model. We can use the `$chat()` method of `client` (an [ellmer](https://cran.r-project.org/package=ellmer) `"Chat"` object), which remembers the context of the previous interaction.

```{r carseats_lm_explain_follow_up}
query <- paste("Could you explain the R-squared values (Multiple R-squared and",
               "Adjusted R-squared) in simpler terms for this car seat sales",
               "model? What does it practically mean for predicting sales?")
client$chat(query)
```

The LLM has provided a more detailed explanation of R-squared, tailored to the `fm_carseats` model and provided context, discussing how much of the variability in `Sales` is explained by the predictors in the model.


### Example 2: Logistic GLM (`glm`) - Pima Indians Diabetes

Let's use the `Pima.tr` data set from the `MASS` package to fit a logistic regression model. This data set is about the prevalence of diabetes in Pima Indian women. Our goal is to identify factors associated with the likelihood of testing positive for diabetes.

```{r pima_glm}
data(Pima.tr, package = "MASS")  # load the Pima.tr data set

# Fit a logistic regression model
fm_pima <- glm(type ~ npreg + glu + bp + skin + bmi + ped + age,
               data = Pima.tr, family = binomial(link = "logit"))
summary(fm_pima)  # print model summary
```

Now, let's provide some additional context to accompany the output when requesting an explanation from the LLM:

```{r pima_glm_context, eval = TRUE}
pima_context <- "
This logistic regression model attempts to predict the likelihood of a Pima
Indian woman testing positive for diabetes. The data is from a study on women of
Pima Indian heritage, aged 21 years or older, living near Phoenix, Arizona. The
response variable 'type' is binary: 'Yes' (tests positive for diabetes) or 'No'.

Predictor variables include:
  - npreg: Number of pregnancies.
  - glu: Plasma glucose concentration in an oral glucose tolerance test.
  - bp: Diastolic blood pressure (mm Hg).
  - skin: Triceps skin fold thickness (mm).
  - bmi: Body mass index (weight in kg / (height in m)^2).
  - ped: Diabetes pedigree function (a measure of genetic predisposition).
  - age: Age in years.

The goal is to understand which of these factors are significantly associated
with an increased or decreased odds of having diabetes. We are particularly
interested in interpreting coefficients as odds ratios.
"

# Establish fresh client connection
client <- ellmer::chat_google_gemini(echo = "none")
```

This time, we'll ask **statlingua** for an explanation, targeting a `"researcher"` with `"moderate"` verbosity. This audience would be interested in aspects like odds ratios and model fit.

```{r pima_glm_explain, results="asis"}
explain(fm_pima, client = client, context = pima_context,
        audience = "researcher", verbosity = "moderate")
```

The above (rendered Markdown) explains the logistic regression coefficients (e.g., for `glu` or `bmi`) in terms of log-odds and odds ratios, discusses their statistical significance, and interprets overall model fit statistics like AIC and deviance. For a researcher, the explanation might also touch upon the implications of these findings for diabetes risk assessment.

Thank you for catching that error! It's crucial to have accurate and reliable examples. The `Pima.tr` data set is a much more suitable choice for this GLM example.

### Example 3: Cox Proportional Hazards Model (`coxph`) - Lung Cancer Survival

Let's model patient survival in a lung cancer study using the `lung` data set from the `survival` package. This is a classic data set for Cox PH models.

```{r lung_coxph, eval = TRUE}
library(survival)

# Load the lung cancer data set (from package survival)
data(cancer)

# Fit a time transform Cox PH model using current age
fm_lung <- coxph(Surv(time, status) ~ ph.ecog + tt(age), data = lung,
     tt = function(x, t, ...) pspline(x + t/365.25))
summary(fm_lung)  # print model summary
```

Here's some additional context to provide for the lung cancer survival model:

```{r lung_coxph_context}
lung_context <- "
This Cox proportional hazards model analyzes survival data for patients with
advanced lung cancer. The objective is to identify factors associated with
patient survival time (in days). The variables include:
  - time: Survival time in days.
  - status: Censoring status (1=censored, 2=dead).
  - age: Age in years.
  - sex: Patient's sex (1=male, 2=female). Note: In the model, 'sex' is treated as numeric; interpretations should consider this. It's common to factor this, but here it's numeric.
  - ph.ecog: ECOG performance score (0=good, higher values mean worse performance).
We want to understand how age, sex, and ECOG score relate to the hazard of death.
Interpretations should focus on hazard ratios. For example, how does a one-unit increase in ph.ecog affect the hazard of death?
"

# Establish fresh client connection
client <- ellmer::chat_google_gemini(echo = "none")
```

Let's get an explanation for a `"manager"` audience, looking for a `"brief"` overview.

```{r lung_coxph_explain, results="asis"}
explain(fm_lung, client = client, context = lung_context,
        audience = "manager", verbosity = "brief")
```

The rendered Markdown output above provides a concise, high-level summary suitable for a manager, focusing on the key predictors of survival and their implications in terms of increased or decreased risk (hazard).

### Example 4: Linear Mixed-Effects Model (`lmer` from [lme4](https://cran.r-project.org/package=lme4)) - Sleep Study

Let's explore the `sleepstudy` data set from the [lme4](https://cran.r-project.org/package=lme4) package. This data set records the average reaction time per day for subjects in a sleep deprivation study. We'll fit a linear mixed-effects model to see how reaction time changes over days of sleep deprivation, accounting for random variation among subjects.

This example will also demonstrate the `style` argument, requesting output as plain text (`style = "text"`) and as a JSON string (`style = "json"`).

```{r sleepstudy_lmer}
library(lme4)

# Load the sleep study data set
data(sleepstudy)

# Fit a linear mixed-effects model allowing for random intercepts and random
# slopes for Days, varying by Subject
fm_sleep <- lmer(Reaction ~ Days + (Days | Subject), data = sleepstudy)
summary(fm_sleep)  # print model summary
```

Now, let's define context for this sleep study model:

```{r sleepstudy_lmer_context}
sleepstudy_context <- "
This linear mixed-effects model analyzes data from a sleep deprivation study.
The goal is to understand the effect of days of sleep deprivation ('Days') on
average reaction time ('Reaction' in ms). The model includes random intercepts
and random slopes for 'Days' for each 'Subject', acknowledging that baseline
reaction times and the effect of sleep deprivation may vary across individuals.
We are interested in the average fixed effect of an additional day of sleep
deprivation on reaction time, as well as the extent of inter-subject
variability.
"

# Establish fresh client connection
client <- ellmer::chat_google_gemini(echo = "none")
```

#### Requesting Plain Text Output (`style = "text"`)

Let's ask **statlingua** for an explanation as plain text, targeting a `"researcher"` with `"moderate"` verbosity.

```{r sleepstudy_lmer_explain_text}
explain(fm_sleep, client = client, context = sleepstudy_context,
        audience = "researcher", verbosity = "moderate", style = "text")
```

#### Requesting JSON Output (`style = "json"`)

Now, let's request the explanation in a structured JSON format (using `style = "json"`). We'll target a `"student"` with `"detailed"` verbosity.

```{r lmer_explain_json_call}
client <- ellmer::chat_google_gemini(echo = "none")
ex <- explain(fm_sleep, client = client, context = sleepstudy_context,
              audience = "student", verbosity = "detailed", style = "json")

# The 'text' component of the statlingua_explanation object now holds a JSON
# string which can be parsed using the jsonlite package
jsonlite::prettify(ex$text)
```

## Inspecting LLM Interaction

If you want to see the exact system and user prompts that **statlingua** generated and sent to the LLM (via [ellmer](https://cran.r-project.org/package=ellmer)), as well as the raw response from the LLM, you can print the [ellmer](https://cran.r-project.org/package=ellmer) `"Chat"` object (defined as `client` in this example) *after* an `explain()` call. The `client` object stores the history of the interaction.

```{r inspect_client}
print(client)
```

This transparency is invaluable for debugging, understanding the process, or even refining prompts if you were developing custom extensions for **statlingua**.

## Conclusion

The **statlingua** package, working hand-in-hand with **ellmer**, provides a powerful and user-friendly bridge to the interpretive capabilities of Large Language Models for R users. By mastering the `explain()` function and its argumentsâ€”especially `context`, `audience`, `verbosity`, and `style`â€”you can transform standard statistical outputs into rich, understandable narratives tailored to your needs.

**Important Considerations:**
* The quality of the LLM's explanation is heavily influenced by the clarity of the `context` you provide and the inherent capabilities of the LLM you choose (in this vignette, we've focused on Google Gemini).
* **LLM Output Variability:** While **statlingua** uses detailed prompts to guide the LLM towards the desired output `style` and content, the nature of generative AI means that responses can vary. The requested `style` is an aim, and while **statlingua** includes measures to clean the output (like removing language fences), the exact formatting and content may not always be perfectly consistent across repeated calls or different LLM versions. Always critically review the generated explanations.
* For the `style = "json"` option, which requests JSON output, ensure the `jsonlite` package is available if you intend to parse the JSON string into an R list within your session.

Remember to critically review all explanations generated by the LLM.

Happy explaining\!
